"""
Test fÃ¼r das behobene UX-Problem

Run this with: streamlit run test_fixed_ux.py
"""

import streamlit as st
from ux_components import URLValidator
from url_detection import detect_url_type

# Page config
st.set_page_config(
    page_title="ğŸ¤– CraCha - Fixed UX Test",
    page_icon="ğŸ¤–",
    layout="wide"
)

# CSS
st.markdown("""
<style>
    .stFormSubmitButton > button {
        background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%) !important;
        color: white !important;
        border: none !important;
        border-radius: 10px !important;
        padding: 0.75rem 2rem !important;
        font-weight: bold !important;
        font-size: 1.1rem !important;
        box-shadow: 0 4px 15px rgba(255, 107, 107, 0.4) !important;
    }
</style>
""", unsafe_allow_html=True)

# Header
st.markdown("""
<div style="text-align: center; padding: 1rem 0; margin-bottom: 1.5rem;">
    <h2 style="color: #667eea;">ğŸ¤– CraCha - UX Problem behoben</h2>
    <p style="color: #666; font-size: 0.9rem;">Enter im URL-Feld startet NICHT mehr den Crawling-Prozess</p>
</div>
""", unsafe_allow_html=True)

# Problem ErklÃ¤rung
st.markdown("### ğŸš¨ Problem behoben:")
st.error("""
**Vorher:** URL eingeben â†’ Enter drÃ¼cken â†’ Crawling startet SOFORT â†’ Einstellungen kÃ¶nnen nicht angepasst werden!
""")

st.success("""
**Jetzt:** URL eingeben â†’ Enter drÃ¼cken â†’ Einstellungen werden geladen â†’ User kann anpassen â†’ Bewusst auf "Erstellen" klicken
""")

# Test Form
with st.form("fixed_ux_test"):
    st.subheader("ğŸŒ Website-Konfiguration")
    
    col1, col2 = st.columns([3, 2])
    
    with col1:
        # URL Validator
        if 'url_validator' not in st.session_state:
            st.session_state.url_validator = URLValidator(timeout=10, debounce_delay=0.5)
        
        url_validator = st.session_state.url_validator
        
        # URL Input - Enter soll NICHT submitten
        url = st.text_input(
            "Website URL: *",
            placeholder="https://docs.example.com",
            help="DrÃ¼cke Enter â†’ Einstellungen werden geladen (KEIN Auto-Submit!)",
            key="test_url_input"
        )
        
        st.caption("ğŸ’¡ **Test:** DrÃ¼cke Enter nach URL-Eingabe - es sollte NICHT crawlen!")
        
        # Real-time validation
        if url and url.strip():
            validation_result = url_validator.render_validation_feedback(url, show_reachability=True, debounced=True)
            st.session_state.url_validation_result = validation_result
        else:
            st.session_state.url_validation_result = None
        
        name = st.text_input(
            "Name: *",
            placeholder="Test Datenbank",
            help="Name fÃ¼r die Wissensdatenbank"
        )
    
    with col2:
        # Intelligente Erkennung
        if url and url.strip():
            url_validation = getattr(st.session_state, 'url_validation_result', None)
            if url_validation and url_validation.is_valid:
                detected_method = detect_url_type(url)
                st.session_state.detected_crawling_method = detected_method
                
                st.info(f"âœ¨ {detected_method.icon} **{detected_method.description}**")
                
                if "recommended_reason" in detected_method.settings:
                    st.caption(f"ğŸ’¡ {detected_method.settings['recommended_reason']}")
                
                # Wichtige BenutzerfÃ¼hrung
                st.success("ğŸ‘‡ Passe die Einstellungen unten an und klicke dann auf 'Erstellen'")
            else:
                st.session_state.detected_crawling_method = None
        else:
            st.session_state.detected_crawling_method = None
    
    # Crawling-Einstellungen
    st.subheader("âš™ï¸ Crawling-Einstellungen")
    
    detected_method = getattr(st.session_state, 'detected_crawling_method', None)
    
    if detected_method:
        col3, col4 = st.columns(2)
        
        with col3:
            if detected_method.method in ["website", "documentation"]:
                # DEFAULT AUF 1 GESETZT
                max_depth = st.slider(
                    "Crawling-Tiefe:",
                    min_value=1, max_value=4, value=1,  # IMMER 1
                    help="Default auf 1 - kann angepasst werden"
                )
                
                st.caption("ğŸ¯ Default: 1 (kann vor dem Crawling angepasst werden)")
                
            elif detected_method.method == "sitemap":
                max_depth = 1
                st.info("ğŸ—ºï¸ Sitemap: Tiefe automatisch auf 1")
                
            else:  # single
                max_depth = 1
                st.info("ğŸ“„ Einzelseite: Tiefe 1")
        
        with col4:
            if detected_method.method == "sitemap":
                max_pages = None
                st.metric("Seiten-Limit", "Automatisch")
                
            elif detected_method.method == "single":
                max_pages = 1
                st.metric("Seiten-Anzahl", "1")
                
            else:
                # DEFAULT AUF 1 GESETZT
                max_pages = st.number_input(
                    "Maximale Seitenzahl:",
                    min_value=1, max_value=100, 
                    value=1,  # IMMER 1
                    help="Default auf 1 - kann angepasst werden"
                )
                
                st.caption("ğŸ¯ Default: 1 (kann vor dem Crawling angepasst werden)")
        
        # ZeitschÃ¤tzung
        if detected_method.method == "single":
            st.info("â±ï¸ ~5-10 Sekunden fÃ¼r eine Seite")
        elif detected_method.method == "sitemap":
            st.info("â±ï¸ AbhÃ¤ngig von Sitemap-GrÃ¶ÃŸe")
        else:
            estimated_time = max_pages * 2 if max_pages else 10
            st.info(f"â±ï¸ ~{estimated_time} Sekunden fÃ¼r {max_pages} Seite(n)")
            
    else:
        st.info("ğŸ’¡ Gib eine URL ein, um Crawling-Einstellungen zu sehen")
        max_depth = 1
        max_pages = 1
    
    # WICHTIG: Nur dieser Button startet den Crawling-Prozess!
    st.markdown("---")
    st.markdown("### ğŸš€ Crawling starten")
    st.info("ğŸ’¡ **Nur dieser Button startet den Crawling-Prozess** - nicht Enter im URL-Feld!")
    
    submitted = st.form_submit_button("ğŸš€ Wissensdatenbank erstellen", use_container_width=True)
    
    if submitted:
        # Validation
        validation_errors = []
        
        if not url or not url.strip():
            validation_errors.append("Website URL ist erforderlich")
        
        if not name or not name.strip():
            validation_errors.append("Name ist erforderlich")
        
        url_validation = getattr(st.session_state, 'url_validation_result', None)
        if url and url_validation and not url_validation.is_valid:
            validation_errors.append(f"URL ungÃ¼ltig: {url_validation.error_message}")
        
        if validation_errors:
            st.error("âŒ **Fehler:**")
            for error in validation_errors:
                st.error(f"â€¢ {error}")
        else:
            st.success("âœ… **UX-Fix funktioniert!**")
            st.balloons()
            
            st.markdown("### ğŸ¯ Konfiguration:")
            st.json({
                "url": url,
                "name": name,
                "detected_type": detected_method.method if detected_method else "unknown",
                "max_depth": max_depth,
                "max_pages": max_pages,
                "note": "Crawling wÃ¼rde jetzt mit diesen angepassten Einstellungen starten!"
            })

# Test Anweisungen
st.markdown("---")
st.markdown("### ğŸ§ª Test-Anweisungen")

st.markdown("""
**1. URL eingeben und Enter drÃ¼cken:**
- âœ… Einstellungen sollten geladen werden
- âŒ Crawling sollte NICHT starten

**2. Einstellungen anpassen:**
- âœ… Tiefe und Seitenzahl kÃ¶nnen geÃ¤ndert werden
- âœ… Defaults stehen auf 1

**3. Bewusst auf "Erstellen" klicken:**
- âœ… Nur dann startet der Crawling-Prozess
- âœ… Mit den angepassten Einstellungen
""")

# Test URLs
st.markdown("### ğŸ”— Test-URLs")
test_urls = [
    "https://docs.python.org",
    "https://example.com/sitemap.xml", 
    "https://streamlit.io/docs",
    "https://example.com/page.html"
]

for i, test_url in enumerate(test_urls):
    if st.button(f"Test: {test_url}", key=f"test_{i}"):
        st.session_state.test_url_input = test_url
        st.info(f"URL gesetzt: {test_url} - DrÃ¼cke Enter im Feld oben!")
        st.rerun()

st.success("ğŸ‰ **UX-Problem behoben:** Enter im URL-Feld startet nicht mehr den Crawling-Prozess!")